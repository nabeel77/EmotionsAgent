Project description:<br/>
Name: Intelligent agent for human like interactions<br/>
Functionality: An agent with vision. Takes the human expressions as an input, processes it and performs an action<br/>  according to the expression. For example, if it got sad expression from the user, then it will tell a joke to make their mood better. Python version 3.7 was used for development.  

How to use:
- Clone the repo. <br/>
- Install the following python modules if not installed.<br/>
  OpenCv, Keras, selenium (for playing youtube videos), speechRecognition (for speech to text), pyttsx3 (for text to speech) beautifulsoup (for web scrapping),requests (for making a url search on browser for  web scrapping, youtubesearchpython (for making a search on youtube). <br/>
- Run EmotionDetection.py file (This is the start point of the intelligent agent for human like interactions i.e. An agent with vision to detect human emotions)
- After initiating the program and opening the face detection window, say "hi assistant" to activate the voice assistant. At this stage, the system will begin detecting facial expressions and execute specific tasks depending on the expression detected.

## Output 
<img width="649" alt="Screenshot 2023-03-07 at 12 29 46" src="https://user-images.githubusercontent.com/35597590/223396910-62645763-c1ad-4a64-9b2c-f26a7fc32a07.png">


<img width="654" alt="Screenshot 2023-03-07 at 12 30 13" src="https://user-images.githubusercontent.com/35597590/223397214-07b20a32-6ee8-464a-94a2-556baf248f35.png">

<img width="305" alt="Screenshot 2023-03-07 at 12 29 18" src="https://user-images.githubusercontent.com/35597590/223397234-1033dcbf-36cd-48f1-b54f-b5d7773dd0e4.png">

<img width="304" alt="Screenshot 2023-03-07 at 12 29 10" src="https://user-images.githubusercontent.com/35597590/223397253-d3c2f20f-bd58-451f-abb4-048f9c358834.png">


